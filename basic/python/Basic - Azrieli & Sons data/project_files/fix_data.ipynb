{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import datetime \n",
    "import os\n",
    "from datetime import timedelta\n",
    "from constants import *\n",
    "from trip_file import TripFile\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read all files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "taarif = pd.read_csv(\"../files/taarif.csv\")\n",
    "taarif = taarif.drop(0).reset_index().drop(columns=[\"index\"]) # first row is nulls\n",
    "new_drivers = pd.read_csv(\"../files/new_drivers.csv\", index_col=0)\n",
    "drivers_with_kviut = pd.read_csv(\"../files/drivers_with_kviut.csv\",index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_drivers(drivers: pd.DataFrame, copy=False) -> pd.DataFrame:\n",
    "    df = drivers\n",
    "    if copy:\n",
    "        df = drivers.copy()\n",
    "\n",
    "    gender_mapping = {\"F\": FEMALE,\n",
    "                    \"M\":MALE,\n",
    "                    \"m\":MALE,\n",
    "                    \"male\":MALE,\n",
    "                    \"boy\":MALE,\n",
    "                    \"unknown\":UNKOWN,\n",
    "                    'woman':FEMALE,\n",
    "                    'girl':FEMALE,\n",
    "                    'none':UNKOWN,\n",
    "                    'female':FEMALE,\n",
    "                    UNKOWN:UNKOWN}\n",
    "\n",
    "    # Make preprocess\n",
    "    df.gender = df.gender.fillna(UNKOWN)\n",
    "    df.gender = df.gender.apply(lambda x: gender_mapping[x])\n",
    "    df.birthdate = pd.to_datetime(df.birthdate, format=\"mixed\")\n",
    "    drivers.birthdate = drivers.birthdate.fillna(datetime.datetime.now())\n",
    "\n",
    "    return df\n",
    "\n",
    "def preprocess_taarif(taarif_df: pd.DataFrame, copy=False) -> pd.DataFrame:\n",
    "    df = taarif_df\n",
    "    if copy:\n",
    "        df = new_drivers.copy()\n",
    "\n",
    "    customers_mapping = {\n",
    "            \"dbs\" : \"yes\",\n",
    "            \"mizranei_kfar_saba\": \"aminach\",\n",
    "            \"telecommunication_ltd\": \"hot\" \n",
    "    }\n",
    "\n",
    "    for customer, new_customer in customers_mapping.items():\n",
    "        # Select the row to duplicate (let's say the first row, index 0)\n",
    "        row_to_duplicate = df[df[\"customer\"] == customer]\n",
    "        # Make a copy of the row\n",
    "        new_row = row_to_duplicate.copy()\n",
    "        new_row[\"customer\"] = new_customer\n",
    "        # Append the modified row to the DataFrame\n",
    "        df = pd.concat([df,pd.DataFrame(new_row)], ignore_index=True)\n",
    "        \n",
    "    return df\n",
    "\n",
    "\n",
    "# Concat the two tables of drivers with and without kviut\n",
    "def concat_drivers_tables(new_drivers, drivers_with_kviut):\n",
    "    drivers_with_kviut[\"kviut\"] = 1\n",
    "    drivers = pd.concat([new_drivers, drivers_with_kviut])\n",
    "    drivers[\"kviut\"] = drivers[\"kviut\"].fillna(0)\n",
    "    return drivers\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "drivers = concat_drivers_tables(new_drivers, drivers_with_kviut)\n",
    "drivers = preprocess_drivers(drivers, copy=True)\n",
    "taarif = preprocess_taarif(taarif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "def get_trip_files(folder, limit=100):\n",
    "    files = np.array(list(os.listdir(folder)))\n",
    "    if limit:\n",
    "        files = files[:limit]\n",
    "    files = np.array([name if not name[-5] == \")\" else name[:-7]+\".csv\" for name in files])\n",
    "    print(\"Processing files....\")\n",
    "    return np.array([TripFile(os.path.join(folder,file)) for file in tqdm(files)])\n",
    "\n",
    "\n",
    "def is_friday(time):\n",
    "    return time.weekday() == 4\n",
    "def is_after_4pm(time):\n",
    "    return time.hour >=16\n",
    "def is_saturday(time):\n",
    "    return time.weekday() == 5\n",
    "def is_before_8pm(time):\n",
    "    return time.hour < 20 or (time.hour == 20 and time.minute == 0 and time.second == 0) \n",
    "\n",
    "def is_after_hour(time, hour):\n",
    "    return time.hour >= hour\n",
    "def is_before_hour(time, hour):\n",
    "    return time.hour < hour or (time.hour == hour and time.minute == 0 and time.second == 0) \n",
    "\n",
    "def count_time_in_weekend(start_time, end_time):\n",
    "    count = 0\n",
    "    current_time = start_time\n",
    "\n",
    "    while current_time < end_time:\n",
    "        next_time = min(end_time, current_time + timedelta(hours=1))\n",
    "        if is_friday(next_time):\n",
    "            if is_after_hour(next_time, 16):\n",
    "                friday_4pm = datetime.datetime(next_time.year, next_time.month, next_time.day, 16, 0)\n",
    "                count += (next_time - max(current_time, friday_4pm)) / timedelta(hours=1)\n",
    "        elif is_saturday(next_time):\n",
    "            if is_before_hour(current_time, 20) or is_friday(current_time): # when next time jumps to midnight the current time is still on friday\n",
    "                saturday_8pm= datetime.datetime(next_time.year, next_time.month, next_time.day, 20, 0)\n",
    "                count += (min(next_time, saturday_8pm) - current_time) / timedelta(hours=1)\n",
    "        \n",
    "        current_time = current_time + timedelta(hours=1)\n",
    "\n",
    "    return count\n",
    "\n",
    "def count_drive_weekend_time(start_time, end_time):\n",
    "    count = 0\n",
    "    current_time = start_time\n",
    "\n",
    "    while current_time < end_time:\n",
    "        next_time = min(end_time, current_time + timedelta(days=1))\n",
    "        if is_friday(current_time) or is_saturday(current_time):\n",
    "            if is_friday(current_time):\n",
    "                weekend_start = datetime.datetime(current_time.year, current_time.month, current_time.day, 22, 0)\n",
    "                weekend_end = datetime.datetime(current_time.year, current_time.month, current_time.day, 16, 0)\n",
    "            else:\n",
    "                weekend_start = datetime.datetime(current_time.year, current_time.month, current_time.day, 22, 0)\n",
    "                weekend_end = datetime.datetime(current_time.year, current_time.month, current_time.day, 22, 0)\n",
    "            interval1 = (start_time, end_time)\n",
    "            # interval2 = (night_start, night_end)\n",
    "            # count += overlap_hours(interval1, interval2)\n",
    "\n",
    "    return count\n",
    "\n",
    "\n",
    "\n",
    "def count_time_at_night(start_time, end_time):\n",
    "    count = 0\n",
    "    current_time = start_time\n",
    "\n",
    "    while current_time < end_time:\n",
    "        next_time = min(end_time, current_time + timedelta(hours=1))\n",
    "        if is_after_hour(next_time, 22):\n",
    "                ten_pm = datetime.datetime(next_time.year, next_time.month, next_time.day, 22, 0)\n",
    "                count += (next_time - max(current_time, ten_pm)) / timedelta(hours=1)\n",
    "        elif is_before_hour(current_time, 6) or is_after_hour(current_time, 22):\n",
    "                six_am = datetime.datetime(next_time.year, next_time.month, next_time.day, 6, 0)\n",
    "                count += (min(next_time, six_am) - current_time) / timedelta(hours=1)\n",
    "        \n",
    "        current_time = current_time + datetime.timedelta(hours=1)\n",
    "    return count\n",
    "\n",
    "\n",
    "def count_drive_night_time(start_time, end_time):\n",
    "    count = 0\n",
    "    current_time = start_time\n",
    "\n",
    "    while current_time < end_time:\n",
    "        next_time = min(end_time, current_time + timedelta(days=1))\n",
    "        night_start = datetime.datetime(current_time.year, current_time.month, current_time.day, 22, 0)\n",
    "        night_end = night_start + timedelta(hours=8)\n",
    "        interval1 = (start_time, end_time)\n",
    "        interval2 = (night_start, night_end)\n",
    "        count += overlap_hours(interval1, interval2)\n",
    "\n",
    "    return count\n",
    "\n",
    "        \n",
    "\n",
    "def overlap_hours(interval1, interval2):\n",
    "    start1, end1 = interval1\n",
    "    start2, end2 = interval2\n",
    "\n",
    "    # Check if intervals overlap\n",
    "    if start1 <= end2 and start2 <= end1:\n",
    "        # Calculate the overlap duration\n",
    "        overlap_start = max(start1, start2)\n",
    "        overlap_end = min(end1, end2)\n",
    "        overlap_duration = overlap_end - overlap_start\n",
    "\n",
    "        return overlap_duration.total_seconds() / 3600\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "def count_time_at_night_and_weekend(start_time, end_time):\n",
    "    count = 0\n",
    "    current_time = start_time\n",
    "\n",
    "    while current_time < end_time:\n",
    "        next_time = min(end_time, current_time + timedelta(hours=1))\n",
    "        if is_after_hour(next_time, 22):\n",
    "            if is_friday(next_time):\n",
    "                ten_pm = datetime.datetime(next_time.year, next_time.month, next_time.day, 22, 0)\n",
    "                count += (next_time - max(current_time, ten_pm)) / timedelta(hours=1)\n",
    "        elif (is_before_hour(current_time, 6) or is_after_hour(current_time, 22)):\n",
    "            if is_saturday(next_time):\n",
    "                six_am = datetime.datetime(next_time.year, next_time.month, next_time.day, 6, 0)\n",
    "                count += (min(next_time, six_am) - current_time) / timedelta(hours=1)\n",
    "        \n",
    "        current_time = current_time + timedelta(hours=1)\n",
    "    return count\n",
    "\n",
    "# Calculate age function\n",
    "def calculate_age(birth_date):\n",
    "    current_date = datetime.datetime.now()\n",
    "    if pd.isnull(birth_date):\n",
    "        return np.nan\n",
    "    age = current_date.year - birth_date.year - ((current_date.month, current_date.day) < (birth_date.month, birth_date.day))\n",
    "    return age\n",
    "\n",
    "def create_trips_df(trip_files):\n",
    "    all_dfs = [trip_file.get_data_frame() for trip_file in trip_files ]\n",
    "    trips_df = pd.concat(all_dfs)\n",
    "    trips_df.end_time = pd.to_datetime(trips_df[\"end_time\"])\n",
    "    trips_df.start_time = pd.to_datetime(trips_df[\"start_time\"])\n",
    "    trips_df[\"kph\"] = trips_df[\"km\"] / ((trips_df[\"end_time\"] - trips_df[\"start_time\"]) / datetime.timedelta(hours=1))\n",
    "\n",
    "    trips_df = trips_df.reset_index().drop(columns=[\"index\"])\n",
    "    trips_df[\"drive_time\"] = (trips_df[\"end_time\"]-trips_df[\"start_time\"]) / timedelta(hours=1)\n",
    "\n",
    "    sunday_morning = datetime.datetime(2024, 11, 5, 6, 0, 0) # sunday 6 am\n",
    "\n",
    "    trips_df.loc[(trips_df[\"start_time\"].isna()) & (trips_df[\"end_time\"].isna()),\"start_time\"] = sunday_morning\n",
    "    \n",
    "    return trips_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing files....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:06<00:00, 165.27it/s]\n"
     ]
    }
   ],
   "source": [
    "trip_files = get_trip_files(\"../files/trips_data\", limit=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips_df = create_trips_df(trip_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing income of drivers...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ron Tohar\\AppData\\Local\\Temp\\ipykernel_13368\\102371248.py:78: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  cum_table = pd.concat([cum_table, df_to_concat], axis=0, join=\"outer\")\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "def calculate_trips_cost(trips_with_fares):\n",
    "    \n",
    "    start = time()\n",
    "    df = trips_with_fares.copy()\n",
    "    # print(\"copying time \", time() - start)\n",
    "    \n",
    "    start = time()\n",
    "    \n",
    "    night_and_weekend_hours =  df.apply(lambda r: count_time_at_night_and_weekend(r.start_time, r.end_time), axis=1)\n",
    "    # print(\"calculate night and weekend time \", time() - start)\n",
    "    start = time()\n",
    "\n",
    "    weekend_hours = df.apply(lambda r: count_time_in_weekend(r.start_time, r.end_time), axis=1) - night_and_weekend_hours\n",
    "    # print(\"calculate weekend time \", time() - start)\n",
    "    start = time()\n",
    "\n",
    "    # night_hours2 = df.apply(lambda r: count_drive_night_time(r.start_time, r.end_time), axis=1) - night_and_weekend_hours\n",
    "    night_hours = df.apply(lambda r: count_time_at_night(r.start_time, r.end_time), axis=1) - night_and_weekend_hours\n",
    "    # print(\"calculate night time \", time() - start)\n",
    "\n",
    "\n",
    "    start = time()\n",
    "    km_per_hour = df[\"km\"] / ((df[\"end_time\"]-df[\"start_time\"]) / timedelta(hours=1))\n",
    "    # print(\"calculate kph \", time() - start)\n",
    "    \n",
    "    start = time()\n",
    "    basic_pay = df.km * df.basic_taarif\n",
    "    extra_pay = df.km.apply(lambda km: max(0, km - 200)) * df.extra_milage\n",
    "    payment_without_bonus = basic_pay + extra_pay\n",
    "    payment_per_km = payment_without_bonus / df[\"km\"]\n",
    "    # print(\"calculate basic payments \", time() - start)\n",
    "\n",
    "\n",
    "    start = time()\n",
    "    # bonus_precentage = ((weekend_hours * df.weekend_bonus) + (night_hours * df.night_bonus) + (night_and_weekend_hours * (df.weekend_bonus + df.night_bonus)))\n",
    "    night_extra_payment = (df.night_bonus / 100) * ((km_per_hour * night_hours) * payment_per_km)\n",
    "    weekend_extra_payment = (df.weekend_bonus / 100) * ((km_per_hour * weekend_hours) * payment_per_km)\n",
    "    night_and_weekend_extra_payment = ((df.weekend_bonus + df.night_bonus) / 100) * ((km_per_hour * night_and_weekend_hours) * payment_per_km)\n",
    "    payment_with_bonus = payment_without_bonus + night_extra_payment + weekend_extra_payment + night_and_weekend_extra_payment\n",
    "    # print(\"calculate bonuses \", time() - start)\n",
    "\n",
    "    df[\"basic_pay\"] = basic_pay\n",
    "    df[\"extra_milage_pay\"] = extra_pay\n",
    "    df[\"weekend_hours\"] = weekend_hours\n",
    "    df[\"night_hours\"] = night_hours\n",
    "    df[\"night_and_weekend_hours\"] = night_and_weekend_hours\n",
    "    df[\"kph\"] = km_per_hour\n",
    "    df[\"weekend_km\"] = weekend_hours * km_per_hour\n",
    "    df[\"night_extra_payment\"] = night_extra_payment\n",
    "    df[\"weekend_extra_payment\"] = weekend_extra_payment\n",
    "    df[\"night_and_weekend_extra_payment\"] = night_and_weekend_extra_payment\n",
    "    df[\"bonus_payment\"] = night_extra_payment + weekend_extra_payment + night_and_weekend_extra_payment\n",
    "    df[\"payment_without_bonus\"] = payment_without_bonus\n",
    "    df[\"payment_with_bonus\"] = payment_with_bonus\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def create_main_table(trip_files=None, trips_df=None):\n",
    "    cum_table = pd.DataFrame(columns=[\"driver_id\",\"month\",\"year\",\"total_income\",\"total_km\"])\n",
    "    if trip_files is None:\n",
    "        trip_files = get_trip_files(\"../files/trips_data\", limit=100)\n",
    "    print(\"Processing income of drivers...\")\n",
    "    # for trip_file in tqdm(trip_files):\n",
    "        \n",
    "    #     trip_df = trip_file.get_data_frame()\n",
    "\n",
    "    trips_with_fares = pd.merge(trips_df, taarif, on=[\"customer\"],how=\"left\")\n",
    "    df = calculate_trips_cost(trips_with_fares)\n",
    "\n",
    "    # print(df)\n",
    "    subset_columns = [\"driver_id\", \"month\", \"year\", \"payment_with_bonus\", \"km\"]\n",
    "    df_to_concat = df[subset_columns]\n",
    "    new_column_names = {'payment_with_bonus': 'total_income', 'km': 'total_km'}\n",
    "    df_to_concat = df_to_concat.rename(columns=new_column_names)\n",
    "    \n",
    "    cum_table = pd.concat([cum_table, df_to_concat], axis=0, join=\"outer\")\n",
    "    cum_table = cum_table.reset_index().drop(columns=[\"index\"])\n",
    "    cum_table = cum_table.groupby([\"driver_id\",\"month\",\"year\"]).sum().reset_index()\n",
    "\n",
    "    drivers_copy = drivers.copy()\n",
    "    drivers_copy[\"age\"] = drivers.birthdate.apply(calculate_age)\n",
    "    drivers_copy = drivers_copy.rename(columns={\"id\":\"driver_id\"})\n",
    "        \n",
    "    cum_table = pd.merge(cum_table, drivers_copy[[\"driver_id\",\"gender\",\"age\",\"vetek\",\"kviut\"]], on=[\"driver_id\"], how=\"left\")\n",
    "\n",
    "    return cum_table\n",
    "\n",
    "table = create_main_table(trip_files, trips_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model to predict missing times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "def preprocess_data_start_time(df1):\n",
    "    df = df1.copy()\n",
    "    df[\"drive_time\"] = (df[\"end_time\"]-df[\"start_time\"]) / timedelta(hours=1)\n",
    "    df[\"day_of_week\"] = df[\"start_time\"].dt.day.astype(\"category\")\n",
    "    df[\"is_weekend\"] = df[\"day_of_week\"].apply(lambda x: x==5 or x==6)\n",
    "    df[\"hour\"] = df[\"start_time\"].dt.hour\n",
    "    df[\"minute\"] = df[\"start_time\"].dt.minute\n",
    "    return df[['day_of_week', 'hour', \"minute\",\"is_weekend\", \"km\",\"kph\"]]\n",
    "\n",
    "def preprocess_data_end_time(df1):\n",
    "    df = df1.copy()\n",
    "    df[\"drive_time\"] = (df[\"end_time\"]-df[\"start_time\"]) / timedelta(hours=1)\n",
    "    df[\"day_of_week\"] = df[\"end_time\"].dt.day.astype(\"category\")\n",
    "    df[\"is_weekend\"] = df[\"day_of_week\"].apply(lambda x: x==5 or x==6)\n",
    "    df[\"hour\"] = df[\"end_time\"].dt.hour\n",
    "    df[\"minute\"] = df[\"end_time\"].dt.minute\n",
    "    return df[['day_of_week', 'hour', \"minute\",\"is_weekend\", \"km\",\"kph\"]]\n",
    "\n",
    "def train_model_start_time(trips_df):\n",
    "    \n",
    "    model = Pipeline([\n",
    "        (\"standard scaler\", StandardScaler()),\n",
    "        ('model', LinearRegression())  # Example model, replace with your own\n",
    "    ])\n",
    "\n",
    "    trips_with_times = trips_df[(~trips_df[\"start_time\"].isna()) & (~trips_df[\"end_time\"].isna())]\n",
    "\n",
    "    data = preprocess_data_start_time(trips_with_times)\n",
    "    X,y = data.drop(columns=[\"kph\"]), data[\"kph\"]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n",
    "\n",
    "def train_model_end_time(trips_df):\n",
    "    \n",
    "    model = Pipeline([\n",
    "        (\"standard scaler\", StandardScaler()),\n",
    "        ('model', LinearRegression())  # Example model, replace with your own\n",
    "    ])\n",
    "\n",
    "    trips_with_times = trips_df[(~trips_df[\"start_time\"].isna()) & (~trips_df[\"end_time\"].isna())]\n",
    "\n",
    "    data = preprocess_data_end_time(trips_with_times)\n",
    "    X,y = data.drop(columns=[\"kph\"]), data[\"kph\"]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_slow_outliers_fixed(trips_df, model):\n",
    "    outliers_slow = trips_df[(trips_df[\"drive_time\"] >30) & ((trips_df[\"kph\"] < 50)) ]\n",
    "    outliers_slow_kph = model.predict(preprocess_data_start_time(outliers_slow).drop(columns=\"kph\"))\n",
    "    outliers_slow_fixed_drive_time = outliers_slow[\"km\"] / outliers_slow_kph\n",
    "    outliers_slow[\"fixed_drive_time\"] = outliers_slow_fixed_drive_time\n",
    "    outliers_slow[\"predicted_kph\"] = outliers_slow_kph\n",
    "    return outliers_slow\n",
    "\n",
    "def get_fast_outliers_fixed(trips_df, model):\n",
    "    outliers = trips_df[(trips_df[\"drive_time\"] >30) & ((trips_df[\"kph\"] > 150))]\n",
    "\n",
    "    drivers_avg_km_df = trips_df[trips_df.driver_id.isin(outliers.driver_id.unique())][[\"driver_id\", \"km\"]].groupby(\"driver_id\").mean()\n",
    "    drivers_avg_km_df = drivers_avg_km_df.rename(columns = {\"km\": \"avg_km\"})\n",
    "    outliers = outliers.merge(drivers_avg_km_df, on=[\"driver_id\"])\n",
    "\n",
    "    outliers_kph = model.predict(preprocess_data_start_time(outliers).drop(columns=\"kph\"))\n",
    "    outliers_fixed_drive_time = outliers[\"avg_km\"] / outliers_kph\n",
    "    outliers[\"fixed_drive_time\"] = outliers_fixed_drive_time\n",
    "    outliers[\"predicted_kph\"] = outliers_kph\n",
    "    return outliers\n",
    "\n",
    "def get_outliers_fixed(trips_df):\n",
    "    model = train_model_start_time(trips_df)\n",
    "    slow_outliers = get_slow_outliers_fixed(trips_df, model)\n",
    "    fast_outliers = get_fast_outliers_fixed(trips_df,model)\n",
    "    outliers_fixed = pd.concat([slow_outliers,fast_outliers])\n",
    "    df = outliers_fixed\n",
    "    df = pd.merge(trips_df, outliers_fixed[[\"driver_id\", \"customer\",\"start_time\",\"end_time\",\"month\",\"year\",\"fixed_drive_time\"]], on=[\"driver_id\", \"customer\",\"start_time\",\"end_time\",\"month\",\"year\"], how=\"left\") \n",
    "    df.loc[~df[\"fixed_drive_time\"].isna(), \"end_time\"] = df[~df[\"fixed_drive_time\"].isna()][\"start_time\"] + df[~df[\"fixed_drive_time\"].isna()][\"fixed_drive_time\"].apply(lambda x: timedelta(hours=x)) # fix end time according to predicted drive time and start time\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ron Tohar\\AppData\\Local\\Temp\\ipykernel_13368\\4199995009.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  outliers_slow[\"fixed_drive_time\"] = outliers_slow_fixed_drive_time\n",
      "C:\\Users\\Ron Tohar\\AppData\\Local\\Temp\\ipykernel_13368\\4199995009.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  outliers_slow[\"predicted_kph\"] = outliers_slow_kph\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ron Tohar\\AppData\\Local\\Temp\\ipykernel_13368\\4199995009.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  outliers_slow[\"fixed_drive_time\"] = outliers_slow_fixed_drive_time\n",
      "C:\\Users\\Ron Tohar\\AppData\\Local\\Temp\\ipykernel_13368\\4199995009.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  outliers_slow[\"predicted_kph\"] = outliers_slow_kph\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input y contains NaN.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[93], line 22\u001b[0m\n\u001b[0;32m     20\u001b[0m trips_df \u001b[38;5;241m=\u001b[39m get_outliers_fixed(trips_df)\n\u001b[0;32m     21\u001b[0m trips_df \u001b[38;5;241m=\u001b[39m get_missing_start_time_fixed(trips_df)\n\u001b[1;32m---> 22\u001b[0m trips_df \u001b[38;5;241m=\u001b[39m \u001b[43mget_missing_end_time_fixed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrips_df\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# trips_df[trips_df[\"end_time\"].isna()]\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[93], line 11\u001b[0m, in \u001b[0;36mget_missing_end_time_fixed\u001b[1;34m(trips_df)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_missing_end_time_fixed\u001b[39m(trips_df):\n\u001b[1;32m---> 11\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model_start_time\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrips_df\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m     data \u001b[38;5;241m=\u001b[39m trips_df[trips_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend_time\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39misna()] \u001b[38;5;66;03m# all rows without end time\u001b[39;00m\n\u001b[0;32m     13\u001b[0m     predicted_kph \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(preprocess_data_start_time(data)\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkph\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "Cell \u001b[1;32mIn[72], line 42\u001b[0m, in \u001b[0;36mtrain_model_start_time\u001b[1;34m(trips_df)\u001b[0m\n\u001b[0;32m     39\u001b[0m X,y \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkph\u001b[39m\u001b[38;5;124m\"\u001b[39m]), data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkph\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     40\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(X, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m---> 42\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1472\u001b[0m     )\n\u001b[0;32m   1473\u001b[0m ):\n\u001b[1;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\pipeline.py:475\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m    473\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    474\u001b[0m         last_step_params \u001b[38;5;241m=\u001b[39m routed_params[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]]\n\u001b[1;32m--> 475\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_final_estimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mlast_step_params\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfit\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    477\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1472\u001b[0m     )\n\u001b[0;32m   1473\u001b[0m ):\n\u001b[1;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_base.py:578\u001b[0m, in \u001b[0;36mLinearRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    574\u001b[0m n_jobs_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs\n\u001b[0;32m    576\u001b[0m accept_sparse \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpositive \u001b[38;5;28;01melse\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsc\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoo\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m--> 578\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    579\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_numeric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmulti_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[0;32m    580\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    582\u001b[0m has_sw \u001b[38;5;241m=\u001b[39m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    583\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_sw:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py:650\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    648\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[0;32m    649\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 650\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    651\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    653\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\validation.py:1279\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1259\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1260\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1261\u001b[0m     )\n\u001b[0;32m   1263\u001b[0m X \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[0;32m   1264\u001b[0m     X,\n\u001b[0;32m   1265\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1276\u001b[0m     input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1277\u001b[0m )\n\u001b[1;32m-> 1279\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[43m_check_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmulti_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmulti_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_numeric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_numeric\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1281\u001b[0m check_consistent_length(X, y)\n\u001b[0;32m   1283\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X, y\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\validation.py:1289\u001b[0m, in \u001b[0;36m_check_y\u001b[1;34m(y, multi_output, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1287\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Isolated part of check_X_y dedicated to y validation\"\"\"\u001b[39;00m\n\u001b[0;32m   1288\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m multi_output:\n\u001b[1;32m-> 1289\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1290\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1291\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1292\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1293\u001b[0m \u001b[43m        \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1294\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1295\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43my\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1296\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1297\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1298\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1299\u001b[0m     estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\validation.py:1049\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m   1043\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1044\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1045\u001b[0m         \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[0;32m   1046\u001b[0m     )\n\u001b[0;32m   1048\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[1;32m-> 1049\u001b[0m     \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1050\u001b[0m \u001b[43m        \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1051\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1052\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1053\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1054\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1056\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy:\n\u001b[0;32m   1057\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_numpy_namespace(xp):\n\u001b[0;32m   1058\u001b[0m         \u001b[38;5;66;03m# only make a copy if `array` and `array_orig` may share memory`\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\validation.py:126\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m--> 126\u001b[0m \u001b[43m_assert_all_finite_element_wise\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    127\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    128\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    129\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nan\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    130\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmsg_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmsg_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    131\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    132\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    133\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\validation.py:175\u001b[0m, in \u001b[0;36m_assert_all_finite_element_wise\u001b[1;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    158\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[0;32m    159\u001b[0m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[0;32m    160\u001b[0m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[0;32m    161\u001b[0m     msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    162\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    163\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    173\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    174\u001b[0m     )\n\u001b[1;32m--> 175\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[1;31mValueError\u001b[0m: Input y contains NaN."
     ]
    }
   ],
   "source": [
    "def get_missing_start_time_fixed(trips_df):\n",
    "    model = train_model_end_time(trips_df)\n",
    "    data = trips_df[trips_df[\"start_time\"].isna()] # all rows without start time\n",
    "    predicted_kph = model.predict(preprocess_data_end_time(data).drop(columns=\"kph\"))\n",
    "    fixed_drive_time = data[\"km\"]/predicted_kph\n",
    "    fixed_drive_timedelta = fixed_drive_time.apply(lambda x: timedelta(hours=x))\n",
    "    trips_df.loc[trips_df[\"start_time\"].isna(), \"start_time\"] = trips_df.loc[trips_df[\"start_time\"].isna(), \"end_time\"] - fixed_drive_timedelta\n",
    "    return trips_df\n",
    "\n",
    "def get_missing_end_time_fixed(trips_df):\n",
    "    model = train_model_start_time(trips_df)\n",
    "    data = trips_df[trips_df[\"end_time\"].isna()] # all rows without end time\n",
    "    predicted_kph = model.predict(preprocess_data_start_time(data).drop(columns=\"kph\"))\n",
    "    fixed_drive_time = data[\"km\"]/predicted_kph\n",
    "    fixed_drive_timedelta = fixed_drive_time.apply(lambda x: timedelta(hours=x))\n",
    "    trips_df.loc[trips_df[\"end_time\"].isna(), \"end_time\"] = trips_df.loc[trips_df[\"end_time\"].isna(), \"start_time\"] + fixed_drive_timedelta\n",
    "    return trips_df\n",
    "\n",
    "trips_df = create_trips_df(trip_files)\n",
    "trips_df = get_outliers_fixed(trips_df)\n",
    "trips_df = get_missing_start_time_fixed(trips_df)\n",
    "trips_df = get_missing_end_time_fixed(trips_df)\n",
    "# trips_df[trips_df[\"end_time\"].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer</th>\n",
       "      <th>driver_id</th>\n",
       "      <th>end_time</th>\n",
       "      <th>km</th>\n",
       "      <th>start_time</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>kph</th>\n",
       "      <th>drive_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12833</th>\n",
       "      <td>yes</td>\n",
       "      <td>653</td>\n",
       "      <td>NaT</td>\n",
       "      <td>454.815943</td>\n",
       "      <td>NaT</td>\n",
       "      <td>april</td>\n",
       "      <td>2015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22709</th>\n",
       "      <td>yes</td>\n",
       "      <td>643</td>\n",
       "      <td>NaT</td>\n",
       "      <td>57.974586</td>\n",
       "      <td>NaT</td>\n",
       "      <td>april</td>\n",
       "      <td>2015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24041</th>\n",
       "      <td>osem</td>\n",
       "      <td>705</td>\n",
       "      <td>NaT</td>\n",
       "      <td>197.556857</td>\n",
       "      <td>NaT</td>\n",
       "      <td>april</td>\n",
       "      <td>2015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24580</th>\n",
       "      <td>intel</td>\n",
       "      <td>52</td>\n",
       "      <td>NaT</td>\n",
       "      <td>99.175149</td>\n",
       "      <td>NaT</td>\n",
       "      <td>april</td>\n",
       "      <td>2015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32551</th>\n",
       "      <td>tnuva</td>\n",
       "      <td>295</td>\n",
       "      <td>NaT</td>\n",
       "      <td>168.653256</td>\n",
       "      <td>NaT</td>\n",
       "      <td>august</td>\n",
       "      <td>2015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46365</th>\n",
       "      <td>tnuva</td>\n",
       "      <td>414</td>\n",
       "      <td>NaT</td>\n",
       "      <td>630.036986</td>\n",
       "      <td>NaT</td>\n",
       "      <td>august</td>\n",
       "      <td>2015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48658</th>\n",
       "      <td>jerusalem_muni</td>\n",
       "      <td>201</td>\n",
       "      <td>NaT</td>\n",
       "      <td>122.775826</td>\n",
       "      <td>NaT</td>\n",
       "      <td>august</td>\n",
       "      <td>2015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             customer  driver_id end_time          km start_time   month  \\\n",
       "12833             yes        653      NaT  454.815943        NaT   april   \n",
       "22709             yes        643      NaT   57.974586        NaT   april   \n",
       "24041            osem        705      NaT  197.556857        NaT   april   \n",
       "24580           intel         52      NaT   99.175149        NaT   april   \n",
       "32551           tnuva        295      NaT  168.653256        NaT  august   \n",
       "46365           tnuva        414      NaT  630.036986        NaT  august   \n",
       "48658  jerusalem_muni        201      NaT  122.775826        NaT  august   \n",
       "\n",
       "       year  kph  drive_time  \n",
       "12833  2015  NaN         NaN  \n",
       "22709  2015  NaN         NaN  \n",
       "24041  2015  NaN         NaN  \n",
       "24580  2015  NaN         NaN  \n",
       "32551  2015  NaN         NaN  \n",
       "46365  2015  NaN         NaN  \n",
       "48658  2015  NaN         NaN  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
